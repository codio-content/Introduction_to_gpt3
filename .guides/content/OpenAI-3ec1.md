##

[OpenAI](https://openai.com/) is on the cutting edge of AI capabilities. OpenAI's mission is to ensure that artificial general intelligence (AGI)—by which we mean highly autonomous systems that outperform humans at most economically valuable work—benefits all of humanity. 

----

**Generative pre-training (GPT)** can acquire knowledge and process long-range dependencies by being trained on a diverse corpus with long stretches of text. Generative in the sense that it can generate text. 
||| Definition
*  **Corpus** refers to one collection of texts.
*  **Corpora** refer to multiple collections of texts.

|||

OpenAI released the complete version of the GPT-2(Generative Pre-trained Transformer) as a successor to GPT with 1.5 billion *parameters* in November 2019. 
 
In order to understand the transformer model, we must know a bit about neural networks. A **neural network** refers to a system of neurons working in tandem. Using a neural network we can have a set of connected input/output units where each connection has a weight associated with it. 
||| 
A **transformer model** is a machine learning method where a sequence of text is processed all at once instead of a word at a time. This allows the connection between words to be more evident. 
|||

OpenAI defines **parameters** as the variables that define the behavior of a machine learning model. In other words, parameters are the settings that determine how a model will learn from data and make predictions.

{Check It!|assessment}(fill-in-the-blanks-2436065814)
